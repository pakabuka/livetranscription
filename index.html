<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Live Audio Transcription</title>
  <style>
    /* Professional Dark Theme (Grey & Black) */
    *, *::before, *::after {
      box-sizing: border-box;
    }
    body {
      margin: 0;
      padding: 0;
      background: #121212;
      color: #E0E0E0;
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    #container {
      max-width: 800px;
      margin: 40px auto;
      background: #1e1e1e;
      border: 1px solid #333;
      border-radius: 8px;
      padding: 20px;
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
    }
    h1 {
      text-align: center;
      margin-bottom: 20px;
      color: #fff;
    }
    .controls {
      text-align: center;
      margin-bottom: 20px;
    }
    button {
      background: #333;
      color: #fff;
      border: none;
      padding: 10px 20px;
      margin: 5px;
      border-radius: 4px;
      cursor: pointer;
      transition: background 0.3s;
    }
    button:hover:not(:disabled) {
      background: #555;
    }
    button:disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }
    /* Larger, scrollable transcript box */
    #transcript {
      width: 100%;
      height: 500px; /* Increased height for more visible text */
      padding: 15px;
      background: #000;
      border: 1px solid #444;
      border-radius: 4px;
      font-size: 18px;
      line-height: 1.5;
      white-space: pre-wrap;
      overflow-y: auto;
      color: #E0E0E0;
    }
  </style>
</head>
<body>
  <div id="container">
    <h1>Live Audio Transcription</h1>
    <div class="controls">
      <button id="startBtn">Start Transcribing</button>
      <button id="stopBtn" disabled>Stop Transcribing</button>
      <button id="downloadBtn" disabled>Download Transcript</button>
    </div>
    <div id="transcript" placeholder="Your transcript will appear here..."></div>
  </div>

  <script>
    // First, try to obtain microphone permission early using getUserMedia.
    // This may help browsers remember the permission (especially on HTTPS/localhost).
    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
      navigator.mediaDevices.getUserMedia({ audio: true })
        .then(function(stream) {
          console.log("Microphone access granted via getUserMedia.");
          // Stop the stream immediately since we just needed to request permission.
          stream.getTracks().forEach(track => track.stop());
        })
        .catch(function(error) {
          console.error("Error obtaining microphone permission:", error);
        });
    }

    // Check if SpeechRecognition is supported.
    window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition || null;
    if (!window.SpeechRecognition) {
      alert("Sorry, your browser does not support Speech Recognition. Please try Google Chrome or a compatible browser.");
    } else {
      // Create a new SpeechRecognition instance.
      const recognition = new window.SpeechRecognition();
      recognition.continuous = true;       // Continue recognition until explicitly stopped.
      recognition.interimResults = true;     // Show interim (live) results.
      recognition.lang = 'en-US';

      // Get DOM elements.
      const startBtn = document.getElementById("startBtn");
      const stopBtn = document.getElementById("stopBtn");
      const downloadBtn = document.getElementById("downloadBtn");
      const transcriptDiv = document.getElementById("transcript");

      // Variable to store the final transcript.
      let finalTranscript = "";

      // Flag to keep track of whether transcription is active.
      let isTranscribing = false;

      // Update the transcript box in real time.
      recognition.onresult = function(event) {
        let interimTranscript = "";
        // Process all the results.
        for (let i = event.resultIndex; i < event.results.length; i++) {
          if (event.results[i].isFinal) {
            finalTranscript += event.results[i][0].transcript;
          } else {
            interimTranscript += event.results[i][0].transcript;
          }
        }
        // Display final transcript along with any interim results (with lower opacity).
        transcriptDiv.innerHTML = finalTranscript + '<span style="opacity:0.6;">' + interimTranscript + '</span>';
        // Auto-scroll to the bottom.
        transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
      };

      recognition.onerror = function(event) {
        console.error("Speech recognition error:", event.error);
      };

      // If the recognition service ends unexpectedly, restart it if we're still transcribing.
      recognition.onend = function() {
        if (isTranscribing) {
          recognition.start();
        }
      };

      // Start transcription.
      startBtn.addEventListener("click", function() {
        transcriptDiv.innerHTML = "";
        finalTranscript = "";
        isTranscribing = true;
        recognition.start();
        startBtn.disabled = true;
        stopBtn.disabled = false;
        downloadBtn.disabled = true;
      });

      // Stop transcription.
      stopBtn.addEventListener("click", function() {
        isTranscribing = false;
        recognition.stop();
        startBtn.disabled = false;
        stopBtn.disabled = true;
        downloadBtn.disabled = false;
      });

      // Download the final transcript as a text file.
      downloadBtn.addEventListener("click", function() {
        const blob = new Blob([finalTranscript], { type: "text/plain" });
        const url = window.URL.createObjectURL(blob);
        const a = document.createElement("a");
        a.style.display = "none";
        a.href = url;
        a.download = "transcript.txt";
        document.body.appendChild(a);
        a.click();
        window.URL.revokeObjectURL(url);
      });
    }
  </script>
</body>
</html>